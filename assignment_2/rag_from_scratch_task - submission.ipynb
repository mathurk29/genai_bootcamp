{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /home/mathurk29/git/EPAM/llm_application_bootcamp_2/.conda/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mathurk29/git/EPAM/llm_application_bootcamp_2/.conda/lib/python3.12/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mathurk29/git/EPAM/llm_application_bootcamp_2/.conda/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mathurk29/git/EPAM/llm_application_bootcamp_2/.conda/lib/python3.12/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mathurk29/git/EPAM/llm_application_bootcamp_2/.conda/lib/python3.12/site-packages (from requests) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in /home/mathurk29/git/EPAM/llm_application_bootcamp_2/.conda/lib/python3.12/site-packages (2.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ollama in /home/mathurk29/git/EPAM/llm_application_bootcamp_2/.conda/lib/python3.12/site-packages (0.4.7)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in /home/mathurk29/git/EPAM/llm_application_bootcamp_2/.conda/lib/python3.12/site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /home/mathurk29/git/EPAM/llm_application_bootcamp_2/.conda/lib/python3.12/site-packages (from ollama) (2.10.3)\n",
      "Requirement already satisfied: anyio in /home/mathurk29/git/EPAM/llm_application_bootcamp_2/.conda/lib/python3.12/site-packages (from httpx<0.29,>=0.27->ollama) (4.8.0)\n",
      "Requirement already satisfied: certifi in /home/mathurk29/git/EPAM/llm_application_bootcamp_2/.conda/lib/python3.12/site-packages (from httpx<0.29,>=0.27->ollama) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /home/mathurk29/git/EPAM/llm_application_bootcamp_2/.conda/lib/python3.12/site-packages (from httpx<0.29,>=0.27->ollama) (1.0.7)\n",
      "Requirement already satisfied: idna in /home/mathurk29/git/EPAM/llm_application_bootcamp_2/.conda/lib/python3.12/site-packages (from httpx<0.29,>=0.27->ollama) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/mathurk29/git/EPAM/llm_application_bootcamp_2/.conda/lib/python3.12/site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/mathurk29/git/EPAM/llm_application_bootcamp_2/.conda/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /home/mathurk29/git/EPAM/llm_application_bootcamp_2/.conda/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /home/mathurk29/git/EPAM/llm_application_bootcamp_2/.conda/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.12.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/mathurk29/git/EPAM/llm_application_bootcamp_2/.conda/lib/python3.12/site-packages (from anyio->httpx<0.29,>=0.27->ollama) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests\n",
    "%pip install numpy\n",
    "%pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List, Tuple\n",
    "import numpy as np\n",
    "import requests as r\n",
    "import ollama\n",
    "from ollama import chat\n",
    "from ollama import ChatResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "BASE_URL = \"http://localhost:11434\"  # Ollama\n",
    "GEN_MODEL = \"Llama3.1\"\n",
    "EMBEDDINGS_MODEL = \"all-minilm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLM:\n",
    "    def __init__(self, model: str, base_url: str) -> None:\n",
    "        self.model = model\n",
    "        # self.endpoint = f\"{base_url}/api/generate\"\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        # Using Python requests lib\n",
    "        # headers = {\"Content-Type\": \"application/json\"}\n",
    "        # data = {\"model\": self.model, \"prompt\": prompt, \"stream\": False}\n",
    "        # response = r.post(self.endpoint, headers=headers, json=data)\n",
    "        # if response.status_code == 200:\n",
    "        #     return response.json()[\"response\"]\n",
    "        \n",
    "        return ollama.generate(model=self.model, prompt=prompt, stream=False).response\n",
    "\n",
    "\n",
    "llm = LLM(model=GEN_MODEL, base_url=BASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate yourself with the test cases below\n",
    "assert llm.generate(\"What is 2+2? Answer only numbers\") == \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathurk29/git/EPAM/llm_application_bootcamp_2/.conda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in input: 23\n",
      "Number of tokens in response: 1\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Initialize the tokenizer for the specific model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# The text to be tokenized\n",
    "input_text = 'assert llm.generate(\"What is 2+2? Answer only numbers\") == \"4\"'\n",
    "response_text = \"4\"\n",
    "\n",
    "# Tokenize the input text\n",
    "input_tokens = tokenizer.encode(input_text, add_special_tokens=False)\n",
    "\n",
    "# Tokenize the response text\n",
    "response_tokens = tokenizer.encode(response_text, add_special_tokens=False)\n",
    "\n",
    "# Print the number of tokens for both input and response\n",
    "print(f\"Number of tokens in input: {len(input_tokens)}\")\n",
    "print(f\"Number of tokens in response: {len(response_tokens)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Generate embeddings using API\n",
    "\n",
    "Here is another example of how to call LLM API to generate embeddings. Embeddings are a different type of model where you can get a vector representation of the text. This is useful for vector search. You can find more information here:\n",
    "\n",
    "- https://platform.openai.com/docs/guides/embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings:\n",
    "    def __init__(self, model: str, base_url: str) -> None:\n",
    "        self.model = model\n",
    "        self.endpoint = f\"{base_url}/api/embed\"\n",
    "\n",
    "    def generate(self, texts: List[str]) -> List[np.ndarray]:\n",
    "\n",
    "        '''\n",
    "        # Using request library\n",
    "        data = {\"model\": self.model, \"input\": texts}\n",
    "        response = r.post(self.endpoint, json=data)\n",
    "        data = response[\"data\"]\n",
    "        result = [\n",
    "            np.array(embedding_data[\"embedding\"]) for embedding_data in data\n",
    "        ]'''\n",
    "\n",
    "        data = ollama.embed(model=self.model, input=texts).embeddings\n",
    "        result = [\n",
    "            np.array(embedding_data) for embedding_data in data\n",
    "        ]\n",
    "\n",
    "        return result\n",
    "\n",
    "embeddings = Embeddings(model=EMBEDDINGS_MODEL, base_url=BASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-6.28815740e-02,  5.49236460e-02,  5.19983880e-02,  8.57613200e-02,\n",
       "        -8.28843400e-02, -7.45355560e-02,  6.84593600e-02,  1.84834130e-02,\n",
       "        -8.20334200e-02, -3.72907400e-02,  1.22046490e-02,  3.67584000e-03,\n",
       "        -4.19703600e-03, -4.38255560e-02,  2.17877100e-02, -5.04259800e-03,\n",
       "         1.95215440e-02, -4.22743970e-02, -1.10398280e-01,  5.23626430e-03,\n",
       "        -5.59179900e-02,  2.79457740e-02, -2.31763100e-02,  2.85418300e-02,\n",
       "        -5.37887850e-02, -5.25930670e-02,  3.37996300e-02,  4.53285430e-02,\n",
       "         2.38065140e-02, -7.31337200e-02,  5.47934620e-02,  1.69697480e-02,\n",
       "         8.13179700e-02, -2.77827450e-03,  1.19441310e-02,  7.34490700e-02,\n",
       "        -9.43206200e-02, -8.13761700e-02,  4.01511100e-02,  6.95719900e-04,\n",
       "        -1.33454520e-02, -5.44682260e-02,  5.13111050e-03, -2.61289300e-02,\n",
       "         3.68050300e-02, -3.38917230e-02,  2.11916770e-02,  5.58499900e-02,\n",
       "         5.78013960e-02, -5.37844000e-03, -6.83696050e-02, -9.03298560e-02,\n",
       "        -4.28502800e-02,  2.35277800e-02,  1.21533126e-01,  3.24207320e-02,\n",
       "        -2.27047320e-02, -2.31682200e-02,  4.87871320e-02, -5.94847350e-02,\n",
       "        -3.40663000e-02,  3.59474800e-02, -8.11965840e-02, -2.20348440e-02,\n",
       "         1.31825710e-02, -4.57412700e-02, -7.04894440e-02, -5.26560250e-02,\n",
       "        -4.79774800e-02, -7.46031800e-02, -2.87607550e-02,  1.28311590e-02,\n",
       "        -4.28463300e-02,  5.33616260e-03, -3.89670800e-02,  1.58830920e-02,\n",
       "         2.01822540e-02,  5.25242700e-03,  9.71084400e-03, -4.67109170e-03,\n",
       "         4.80816770e-02, -7.30908700e-02, -5.03893500e-02,  9.74158700e-03,\n",
       "         1.35133180e-02,  3.94216770e-04,  1.97061080e-02,  6.25004000e-02,\n",
       "        -1.82548900e-02,  3.10365800e-02, -8.87693400e-02,  4.81585820e-02,\n",
       "         2.61775650e-02, -1.14866120e-02, -9.93981500e-02, -2.72615070e-02,\n",
       "         7.62060600e-02, -2.03531450e-03, -1.23535305e-01,  2.97943800e-01,\n",
       "         5.62435050e-02,  7.84724950e-02,  1.12016710e-02,  5.23994970e-02,\n",
       "        -1.18660720e-03,  9.40743300e-04, -5.43233300e-02,  2.67876050e-02,\n",
       "        -1.21333780e-02,  1.07740720e-02, -4.17316300e-05, -3.55614100e-02,\n",
       "        -3.19882200e-02,  1.63118970e-02,  8.66903100e-02,  1.82096360e-02,\n",
       "        -1.09599440e-02,  4.97708430e-02,  2.26059520e-02,  4.73588300e-05,\n",
       "         1.48933100e-02, -1.11877220e-02,  5.65666240e-03, -4.05899200e-03,\n",
       "         3.20248170e-03,  2.37835600e-02,  1.80457030e-02, -5.84998470e-33,\n",
       "         5.60936500e-02, -3.45967670e-02,  3.31066360e-02,  1.67768390e-01,\n",
       "        -3.10974880e-02, -4.75214100e-03, -6.11088700e-02, -6.27173560e-02,\n",
       "         2.74330860e-02,  6.37140650e-02,  4.33199000e-02,  6.08402830e-02,\n",
       "        -1.81544350e-02,  4.27940300e-02,  1.90743950e-02,  8.80148400e-02,\n",
       "        -3.90425300e-02,  4.41754200e-02, -5.00327260e-03,  5.09124500e-02,\n",
       "        -5.43235000e-02,  1.12433370e-02,  2.66951640e-02,  7.49844460e-02,\n",
       "         4.87045420e-02, -4.35426100e-02,  1.32648520e-02, -1.02617815e-01,\n",
       "         5.20691760e-02,  2.23018230e-02, -2.98682000e-02, -4.21374330e-02,\n",
       "         2.29672960e-02,  3.96351140e-02,  9.00243700e-03,  2.09337400e-02,\n",
       "         5.09712400e-03, -6.27662400e-02, -5.02034460e-02, -5.11280870e-03,\n",
       "        -5.34637000e-02,  2.97015830e-02,  2.17317530e-02, -2.05127040e-02,\n",
       "         2.38946500e-02,  5.74224000e-03, -1.26959810e-03,  2.26346520e-02,\n",
       "         3.06708160e-03,  3.09881290e-02, -5.28877700e-02,  1.86355300e-02,\n",
       "        -1.40151930e-01,  4.14299330e-02, -1.01676070e-02, -1.15846150e-02,\n",
       "        -3.35077530e-02, -5.05755100e-02,  4.69160700e-02,  2.46635210e-02,\n",
       "         3.35466680e-02,  1.11771430e-01, -4.03993540e-02, -4.38462400e-03,\n",
       "        -8.09726800e-02, -5.61450650e-02,  3.82963700e-02,  1.14231720e-02,\n",
       "         6.88110800e-02, -3.82451230e-02, -4.61086930e-02, -1.63162370e-02,\n",
       "         2.45365520e-02,  1.16534730e-02,  8.31787900e-03,  3.90613380e-02,\n",
       "         2.61679800e-02,  1.04827650e-02,  4.28803670e-02, -4.63025760e-02,\n",
       "         6.47290800e-03,  4.44250440e-02, -1.87853630e-02,  7.33740900e-03,\n",
       "         5.62444330e-02,  5.35214320e-02, -2.13991420e-02, -8.44723500e-02,\n",
       "        -1.26555730e-02, -3.95470560e-02, -5.81100200e-02,  3.13303550e-02,\n",
       "         4.53712050e-02,  1.18305070e-02, -1.76908690e-02,  4.58236860e-33,\n",
       "         1.31406560e-01,  7.92397800e-02, -9.48938200e-02, -2.43178050e-02,\n",
       "        -5.58002960e-02, -9.10528000e-03, -3.21052100e-02,  1.13719545e-01,\n",
       "        -1.44439850e-01,  8.48929600e-03,  3.05865740e-02, -1.24315520e-02,\n",
       "         7.01945200e-02,  2.80918300e-02,  4.08255760e-02,  1.98249020e-02,\n",
       "         1.42942440e-01,  5.68797850e-02, -4.00977200e-02, -1.78196860e-02,\n",
       "        -6.13058470e-02,  7.71935850e-04, -5.49240600e-02, -7.21268400e-03,\n",
       "        -5.13770730e-04, -1.30675180e-02, -2.20486380e-03,  5.85236200e-02,\n",
       "        -9.97441300e-02, -2.55909190e-02,  7.85607400e-02,  2.04178700e-02,\n",
       "        -4.55045900e-03,  3.02033460e-02,  1.68251470e-02,  9.14367960e-02,\n",
       "         1.68294900e-02, -7.99385000e-02,  4.25465960e-02, -8.45738650e-02,\n",
       "        -2.38410800e-02,  4.70430300e-02,  2.46604100e-03,  1.09298880e-01,\n",
       "        -3.38784640e-02, -6.42168200e-02, -3.77598260e-02,  2.91025710e-02,\n",
       "        -4.24562360e-02,  1.59560200e-02, -9.05465560e-02, -5.56602500e-02,\n",
       "         2.26834340e-02,  7.96067300e-03, -2.24793000e-02,  2.20326560e-02,\n",
       "        -2.52530030e-02,  3.04291620e-02,  1.01369405e-02, -1.84418700e-02,\n",
       "         1.70531940e-02,  7.63684300e-02,  4.15890370e-02,  8.74664400e-02,\n",
       "        -1.20970070e-02,  3.11187600e-02, -3.21889150e-02,  1.28053910e-02,\n",
       "         1.34133990e-02, -2.96283030e-02,  3.67577970e-02, -5.94210860e-03,\n",
       "        -1.11776170e-02,  3.86470220e-02, -2.07518840e-02, -1.13198200e-02,\n",
       "        -2.37786270e-02, -9.89929700e-03, -2.29775030e-02,  1.20684910e-02,\n",
       "        -1.06066510e-02,  5.14405930e-02, -2.77306440e-02, -1.56196770e-04,\n",
       "         9.26516660e-04, -3.17463760e-02,  5.10882060e-02,  4.42395200e-02,\n",
       "        -3.83047700e-03, -4.16217560e-02,  2.89947780e-02,  3.30138360e-02,\n",
       "        -1.51739260e-02, -3.01190450e-04, -4.40642760e-02, -1.47983300e-08,\n",
       "        -8.54916500e-03,  7.66457450e-05,  1.66262720e-02,  5.93275400e-02,\n",
       "         4.55405670e-02,  3.32310420e-02, -9.34544650e-02, -3.89796720e-02,\n",
       "        -2.06718050e-02,  1.24843650e-02,  6.97757500e-02,  7.90751500e-02,\n",
       "        -7.18340650e-02, -4.75084870e-03,  8.80188900e-02,  4.75041570e-02,\n",
       "        -5.22228370e-02, -7.66582040e-03, -5.77499570e-02, -9.31138200e-02,\n",
       "        -4.38317600e-03,  1.13708340e-03,  2.45137000e-02, -6.42380340e-02,\n",
       "        -3.27987850e-03, -2.78256980e-02, -3.53035480e-02,  2.51429100e-02,\n",
       "        -9.89672100e-03,  1.30991980e-02,  1.10705290e-03,  1.78103240e-01,\n",
       "        -3.60010040e-02, -7.63125200e-03, -3.22885000e-02, -4.23006300e-02,\n",
       "         4.68178200e-03,  2.85385140e-02,  7.45548100e-02, -1.48091940e-02,\n",
       "        -5.61927150e-02,  2.71432600e-02, -1.12298370e-02, -1.01674095e-01,\n",
       "        -1.96905640e-02,  2.71832960e-02,  3.49933200e-02, -8.16652600e-02,\n",
       "        -1.22943490e-03, -7.62572100e-02, -3.99185530e-02,  4.07066680e-02,\n",
       "         6.01983500e-02,  7.26297000e-02,  6.95448700e-02,  8.91027150e-02,\n",
       "         1.60761000e-02, -1.49078140e-02, -4.67446820e-02, -1.34749520e-02,\n",
       "         6.51521760e-02,  5.09086600e-02,  5.16139160e-02,  7.16402700e-03]),\n",
       " array([-3.03185250e-02,  3.15599900e-02, -6.34567500e-02, -1.38219330e-02,\n",
       "         3.51836050e-02, -8.10960800e-02,  1.03049480e-01,  9.40494600e-03,\n",
       "         2.44634520e-02,  3.21192220e-03,  8.24804700e-02, -6.81490000e-02,\n",
       "         2.94183000e-02,  5.79127900e-02, -9.61986200e-02, -9.29042400e-03,\n",
       "        -8.11577740e-02, -8.83959400e-02, -1.44404010e-01, -8.99385960e-02,\n",
       "        -3.36084550e-02,  6.95960700e-02,  1.56304930e-02,  5.31583840e-02,\n",
       "        -4.21151520e-02,  8.25757460e-02,  2.86999830e-02,  7.21439940e-02,\n",
       "         1.11981340e-02, -5.86290170e-02, -1.68170050e-02,  3.35371050e-02,\n",
       "         6.68692440e-02, -2.52199710e-02, -6.38393800e-02,  8.11183100e-03,\n",
       "        -2.68976060e-02, -3.71509500e-03,  7.61397460e-03, -1.13740270e-02,\n",
       "         7.95599150e-02, -5.31376450e-02, -1.08012620e-02, -4.62284760e-02,\n",
       "        -2.96208000e-02, -1.23440940e-02, -9.90809100e-03,  9.63687200e-03,\n",
       "         4.41766160e-03,  3.59631330e-02, -6.48309500e-02, -4.68310340e-02,\n",
       "        -3.08261480e-02, -3.38807900e-03, -1.06267450e-02, -3.16225550e-02,\n",
       "         2.64633450e-02, -1.31072070e-02,  5.36368940e-02, -1.36319180e-02,\n",
       "         6.51762900e-02, -1.45837795e-02, -1.07967050e-04,  6.56656250e-02,\n",
       "         1.29298000e-01,  1.74187870e-02,  6.35008140e-03,  1.29375090e-01,\n",
       "        -4.11713830e-02, -7.58429600e-02,  7.86381900e-03, -1.54955560e-02,\n",
       "         2.54428950e-02,  2.97852330e-02,  1.42194545e-02,  7.40441030e-03,\n",
       "         9.12872900e-03, -7.50630260e-03,  4.74329100e-02,  7.20869500e-02,\n",
       "         7.78842000e-02, -3.87830660e-02, -4.06245740e-02,  4.92158050e-02,\n",
       "         3.07043870e-02, -5.19500600e-02, -7.61912700e-03, -2.82899010e-02,\n",
       "        -3.19623870e-02, -9.44242350e-03, -6.47465800e-02, -6.55174260e-02,\n",
       "         4.58547850e-02,  4.61375530e-02, -1.16900176e-01,  3.79591660e-02,\n",
       "         6.45420000e-02, -5.60037640e-02, -6.54999240e-02,  2.37296370e-01,\n",
       "         1.63633460e-03,  4.24490600e-03,  6.80470900e-02,  6.16593200e-02,\n",
       "         5.76425460e-02,  9.41573100e-03, -8.02758600e-02,  7.09087900e-02,\n",
       "        -5.87948300e-02, -5.77561930e-02, -7.88540000e-02,  1.12204080e-02,\n",
       "         3.40211840e-02, -3.71733980e-02, -2.85173560e-02, -2.92894400e-02,\n",
       "         4.31399400e-02,  3.82238160e-03, -4.53794200e-02, -1.06988330e-02,\n",
       "         2.21375450e-02, -1.48786320e-02,  3.33483220e-02,  2.60316200e-02,\n",
       "        -2.44090000e-02, -3.79290320e-02,  4.99884150e-02, -4.74032350e-33,\n",
       "         6.60274100e-02, -8.67834700e-02,  5.27197350e-02,  5.01795630e-02,\n",
       "         3.60771500e-02,  4.54426070e-02, -2.25416370e-02, -1.58276040e-02,\n",
       "        -1.74208260e-02,  5.08206370e-02, -1.17836270e-02,  1.37889180e-02,\n",
       "        -5.76514380e-02,  6.04014140e-02,  1.47814380e-01,  3.72882080e-02,\n",
       "         2.29131320e-02,  3.27930100e-02, -2.23177500e-02,  1.09733610e-01,\n",
       "        -5.32602240e-03,  3.05900830e-02, -2.68933460e-02,  2.57531100e-02,\n",
       "        -2.65613180e-02,  3.32243960e-02,  4.77302960e-03, -4.09439400e-02,\n",
       "         5.57709200e-02,  1.04841080e-02,  8.14595300e-02,  1.50022210e-02,\n",
       "        -5.17999750e-02, -3.08526470e-02,  8.69519400e-03, -3.94864400e-02,\n",
       "        -1.01977240e-03, -3.50115040e-02, -3.17909100e-02, -5.93236240e-02,\n",
       "        -1.36876940e-02,  2.52533670e-02, -2.59272980e-02,  1.30440710e-02,\n",
       "         2.70626620e-02,  3.82049600e-02,  8.97780300e-02,  5.08205500e-02,\n",
       "        -3.85222360e-02,  7.65747650e-02, -4.21450700e-02, -3.66210230e-02,\n",
       "        -4.76943030e-02, -2.28283000e-02,  1.87960320e-02,  1.20182060e-02,\n",
       "         6.15862500e-03,  1.73219240e-02, -1.01121260e-02,  7.04362840e-02,\n",
       "         1.28878510e-03,  6.38086900e-02,  1.84997580e-02, -9.76250300e-03,\n",
       "         7.41021660e-03, -5.04465200e-02,  1.90195160e-02, -3.05512100e-02,\n",
       "         2.95161880e-02, -2.12200800e-02, -6.56639300e-02,  5.26572470e-02,\n",
       "         2.26581060e-02,  3.35693360e-02,  2.54173320e-02,  9.36450200e-04,\n",
       "         1.39461380e-01,  1.07968920e-03, -6.03820700e-02,  5.26335720e-02,\n",
       "        -7.51829500e-03,  1.21526740e-02,  5.11241330e-02, -1.16371730e-02,\n",
       "         8.16548240e-02, -9.46877150e-03, -3.02890150e-02, -7.23143150e-02,\n",
       "         2.57118530e-02,  2.12496630e-02, -1.54922490e-01,  2.71718130e-02,\n",
       "         4.84987650e-02, -3.48242630e-02, -2.05104030e-02,  4.00593600e-33,\n",
       "        -1.93075400e-02, -1.61949660e-02,  3.15369740e-02,  5.21629800e-02,\n",
       "         1.34012075e-02, -6.45867500e-02, -6.05720900e-02,  9.12521900e-02,\n",
       "        -1.90865170e-02,  1.02420494e-01, -1.96226440e-02,  1.18630230e-02,\n",
       "         1.19675380e-01,  3.98404040e-02, -2.61706280e-02, -4.79914800e-02,\n",
       "         7.07140700e-02, -8.01747140e-02, -4.28737840e-03,  1.24691070e-02,\n",
       "         1.40194185e-02, -1.00340895e-01, -3.04220800e-02, -4.24812470e-02,\n",
       "        -7.32303500e-02,  6.77379400e-02,  3.45947370e-02, -2.43112150e-02,\n",
       "        -3.67517800e-02,  5.65886760e-02,  1.20597540e-03,  2.26479840e-02,\n",
       "        -1.02337240e-01, -1.60396300e-02, -2.83900700e-02,  7.90639600e-02,\n",
       "        -7.07597360e-02,  3.53466050e-02,  1.53290230e-02, -2.39828060e-02,\n",
       "        -9.63549600e-03, -5.77286000e-02, -4.25391300e-02,  6.48976800e-02,\n",
       "        -1.27517800e-01, -1.20426120e-02, -4.17751000e-02,  3.61469870e-02,\n",
       "         4.21399140e-02, -1.05445450e-02, -7.97069900e-02,  5.30673530e-02,\n",
       "         5.08854450e-03, -7.55988800e-02,  7.74691350e-04, -2.40853410e-02,\n",
       "        -8.59610600e-02,  2.15014930e-02,  3.52840950e-02,  4.68856880e-02,\n",
       "         7.54046000e-03,  3.28774840e-03, -5.23843200e-02,  9.58343300e-02,\n",
       "        -3.57895000e-02, -4.23083450e-03,  7.26743970e-03,  6.00492200e-02,\n",
       "        -7.63511200e-03, -2.82494870e-02,  3.65092050e-02,  3.01689890e-03,\n",
       "        -7.12876100e-02, -2.49855610e-02, -4.22069100e-02,  4.00686900e-02,\n",
       "        -4.79895320e-02,  2.96634270e-02,  4.55145050e-02,  1.92463790e-02,\n",
       "         3.91495640e-02, -2.01155690e-03,  2.74426560e-03,  6.12800340e-02,\n",
       "        -5.97815140e-02,  1.16368470e-02,  1.89831310e-02,  8.56586000e-02,\n",
       "        -4.73907330e-02, -5.53948060e-03, -8.40320400e-02, -1.82498970e-02,\n",
       "        -4.84542730e-02, -2.15318330e-02, -5.07648100e-02, -1.26562380e-08,\n",
       "        -2.80949960e-02, -9.62352030e-04,  2.32571030e-02,  1.10459110e-02,\n",
       "        -6.02774650e-03,  6.05395900e-02,  6.94586400e-02, -1.50237270e-02,\n",
       "        -5.29629550e-02,  4.35569900e-02,  6.44935200e-02,  5.02236040e-02,\n",
       "         2.75498670e-02,  6.88985200e-02, -2.67355570e-02, -3.65996960e-02,\n",
       "        -2.65211220e-02,  2.46625200e-02, -8.93479100e-03,  9.31802900e-02,\n",
       "         1.00542940e-03,  1.40485750e-02,  3.82560380e-02, -6.37577600e-02,\n",
       "         1.30836150e-02, -6.95759650e-02, -3.53003260e-02,  2.38518170e-02,\n",
       "        -3.03413100e-02, -1.42069250e-01,  4.68098400e-02,  2.91926260e-02,\n",
       "         8.85062600e-03, -1.64875670e-02, -4.67007000e-02, -4.71940100e-02,\n",
       "        -3.30459200e-02,  1.05645700e-02,  8.14278600e-03, -2.33583660e-02,\n",
       "        -2.96096020e-02,  4.21802100e-02, -3.29581440e-03, -3.86729100e-02,\n",
       "        -1.25195330e-02,  1.29607795e-02,  6.15439270e-02, -1.92083740e-02,\n",
       "        -7.19615260e-03, -6.37526250e-03, -1.28547030e-01,  6.53240460e-03,\n",
       "         5.94342430e-02, -3.82943500e-02,  1.08692730e-01, -9.74954340e-04,\n",
       "         8.63264500e-03,  4.80912070e-02, -2.98991180e-02,  6.59051000e-02,\n",
       "         1.39534580e-01, -4.36699170e-02, -4.99483200e-02, -7.76493550e-03])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.generate([\"Hello\", \"world\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate yourself with the test cases below\n",
    "test_embeddings = embeddings.generate([\"Hello\", \"world\"])\n",
    "\n",
    "assert len(test_embeddings) == 2\n",
    "assert type(test_embeddings) == list\n",
    "assert type(test_embeddings[0]) == np.ndarray\n",
    "assert type(test_embeddings[1]) == np.ndarray\n",
    "assert test_embeddings[0].shape == (384,)\n",
    "assert test_embeddings[1].shape == (384,)\n",
    "assert np.all(test_embeddings[0] != test_embeddings[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Implement chunking in Python\n",
    "\n",
    "In this step, we will implement chunking in Python. Chunking is a process of splitting text into smaller parts. This is useful when you have long text and you want to process it in parts. This is useful for vector search when you want to search for similar documents. For this implementation, we will split text by word count. Here you can implement more advanced chunking algorithms like splitting by sentences or paragraphs or adding some overlap between chunks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_chunks(text: str, chunk_size: int = 30) -> list:\n",
    "    \"\"\"\n",
    "    Split the input text into chunks of the specified size.\n",
    "\n",
    "    Args:\n",
    "    text (str): The input text to split.\n",
    "    chunk_size (int): The size in words of each chunk.\n",
    "    \"\"\"\n",
    "\n",
    "    chunks = []\n",
    "    tokens = text.split()\n",
    "    for i in range(0, len(tokens), chunk_size):\n",
    "        chunks.append(\" \".join(tokens[i : i + chunk_size]))\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate yourself with the test cases below\n",
    "test_chunks = split_into_chunks(\"hello world, how are you?\", chunk_size=2)\n",
    "\n",
    "assert len(test_chunks) == 3, f\"Expected 3 chunks but got {len(test_chunks)}\"\n",
    "assert (\n",
    "    len(test_chunks[0].split()) == 2\n",
    "), f\"Expected 2 words in first chunk but got {len(test_chunks[0].split())}\"\n",
    "assert test_chunks == [\n",
    "    \"hello world,\",\n",
    "    \"how are\",\n",
    "    \"you?\",\n",
    "], f\"Got different result {test_chunks}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create a similarity measure using cosine similarity\n",
    "\n",
    "The core idea of vector search is to find similar vectors. This method is called KNN (k-nearest neighbors) search. In this step, we will implement cosine similarity. Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space that measures the cosine of the angle between them. It is calculated as the dot product of the vectors divided by the product of the magnitudes of the vectors.\n",
    "\n",
    "Here’s the cosine similarity formula:\n",
    "\n",
    "$$\n",
    " \\text{cosine\\_similarity} = \\frac{\\mathbf{A} \\cdot \\mathbf{B}}{\\|\\mathbf{A}\\| \\|\\mathbf{B}\\|} \n",
    "$$\n",
    "Where:\n",
    "\n",
    "- $\\mathbf{A} \\cdot \\mathbf{B}$  is the dot product of vectors  $\\mathbf{A}$  and  $\\mathbf{B}$.\n",
    "- $\\|\\mathbf{A}\\|$  is the norm (magnitude) of vector  $\\mathbf{A}$.\n",
    "- $\\|\\mathbf{B}\\|$  is the norm (magnitude) of vector  $\\mathbf{B}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the cosine similarity between two vectors.\n",
    "\n",
    "    Args:\n",
    "    a (np.ndarray): The first vector.\n",
    "    b (np.ndarray): The second vector.\n",
    "    \"\"\"\n",
    "    # TODO Implement the function to calculate the cosine similarity between two vectors\n",
    "    product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "\n",
    "    return product / (norm_a * norm_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate yourself with the test cases below\n",
    "test_distance = cosine_similarity(np.array([1, 2, 3]), np.array([4, 5, 6]))\n",
    "assert (\n",
    "    round(test_distance, 2) == 0.97\n",
    "), \"The cosine similarity between the same vectors should be 0.97\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Implement vector retrieval\n",
    "\n",
    "In this step, we will implement vector retrieval. This is a process of finding similar vectors to the query vector. This is useful when you have a lot of documents and you want to find the most similar ones to the query. This is useful for building search engines. In this implementation, we will use brute force search. This is not efficient for large datasets, but it is good for educational purposes. In real-world scenarios, you would use specialized libraries like Faiss or Annoy or vector search engines like Milvus, Qdrant, and pgvector.\n",
    "\n",
    "It includes the following steps:\n",
    "- add_documents\n",
    "  - for each document, generate embeddings using API\n",
    "  - store the embeddings and document\n",
    "- retrieve_most_similar\n",
    "  - generate embeddings for the query\n",
    "  - calculate cosine similarity between the query and all documents\n",
    "  - return the most similar documents based on the cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Retriever:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vectorizer: Callable[[List[str]], List[Tuple[str, np.ndarray]]],\n",
    "        similarity_metric: Callable[[np.ndarray, np.ndarray], float],\n",
    "    ):\n",
    "        self.vectorizer = vectorizer\n",
    "        self.similarity_metric = similarity_metric\n",
    "        self.documents = []\n",
    "        self.vectors = []\n",
    "\n",
    "    def add_documents(self, documents: List[str]):\n",
    "        \"\"\"\n",
    "        Add documents to the retriever.\n",
    "\n",
    "        Args:\n",
    "        documents (List[str]): The list of documents to add.\n",
    "        \"\"\"\n",
    "        self.documents.extend(documents)\n",
    "        self.vectors = self.vectorizer(documents)\n",
    "\n",
    "    def retrieve_most_similar(\n",
    "        self, query: str, vectors: List[float], top_k: int = 1\n",
    "    ) -> List[dict]:\n",
    "        \"\"\"\n",
    "        Retrieve the most similar chunk to the query from the list of vectors.\n",
    "\n",
    "        \"\"\"\n",
    "        query_vector = self.vectorizer(\n",
    "            query\n",
    "        )\n",
    "        similarities = [\n",
    "            self.similarity_metric(query_vector, doc_vector)[0]\n",
    "            for doc_vector in vectors\n",
    "        ]\n",
    "        top_k_indices = np.argsort(similarities)[-top_k:][\n",
    "            ::-1\n",
    "        ]\n",
    "        return [\n",
    "            {\"document\": self.documents[i], \"similarity\": similarities[i]}\n",
    "            for i in top_k_indices\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Putting it all together, building RAG (Retriever Answer Generator)\n",
    "\n",
    "How we can use all these components to build the RAG model? RAG is a model that can generate answers based on the documents. It consists of two parts:\n",
    "- Retriever: find the most relevant documents\n",
    "- Generator: generate the answer based on the documents\n",
    "\n",
    "\n",
    "The whole process contains two stages: offline and online. In the offline stage, you split documents into chunks, generate embeddings for all chunks and store them. In the online stage, you generate embeddings for the query and find the most similar chunks. Then you generate the answer based on the most similar documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lets take the story and build assistant to answer the questions based on the story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "story = \"\"\"In a bustling city, tucked away in a cozy apartment, lived a small cat named Whiskers. Whiskers was a curious and adventurous feline, always exploring nooks and crannies, but one day, his attention was caught by something entirely new—a shiny, sleek iPhone that belonged to his owner, Emma.\n",
    "\n",
    "Emma was a tech enthusiast who loved her gadgets, especially her iPhone. She used it for everything, from ordering groceries to video chatting with friends. One lazy afternoon, Emma left her iPhone on the coffee table and stepped out for a quick run to the store, leaving Whiskers alone in the apartment.\n",
    "\n",
    "Whiskers, intrigued by the glowing screen, padded over to the device. With a gentle paw, he nudged it, causing the screen to light up. The cat’s eyes widened as he saw the moving images and colorful icons. As he batted at the screen, the phone unlocked, revealing a treasure trove of apps and pictures.\n",
    "\n",
    "The first interesting pivot occurred when Whiskers accidentally opened Emma’s video editing app. As he pounced on the screen, he unknowingly began creating a video. Clips of Emma dancing, snippets of her travels, and hilarious moments of Whiskers himself filled the timeline. With a few more taps and swipes, the video was complete and, unbeknownst to Whiskers, uploaded to Emma’s social media.\n",
    "\n",
    "The next twist came when Emma’s friends started commenting and sharing the video, amazed at the unexpected compilation. Emma, still unaware of the viral sensation, returned home to find her phone on the floor and Whiskers curled up beside it, purring contentedly.\n",
    "\n",
    "As Emma picked up her phone, notifications flooded the screen. Confused, she opened the video app and saw the masterpiece Whiskers had inadvertently created. She couldn’t help but laugh at the serendipity of it all. Emma decided to embrace the moment and posted a thank you message to Whiskers on her social media, giving him full credit for the unexpected entertainment.\n",
    "\n",
    "However, the story didn’t end there. The final pivot happened when a local news channel got wind of the viral video. They reached out to Emma, eager to feature Whiskers on their evening segment. Emma agreed, and soon, Whiskers was a local celebrity. The small cat who had simply been curious about an iPhone had now become a beloved figure in the community.\n",
    "\n",
    "Whiskers enjoyed the attention, but more than that, he relished the extra treats and cuddles from Emma. The iPhone, once just a gadget, became a bridge to a new adventure, reminding Emma and Whiskers that sometimes, the most unexpected moments bring the greatest joy.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before building RAG, let's first check if LLM itself can NOT answer the question "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The iPhone is a product of Apple Inc., an American multinational technology company based in Cupertino, California. As such, the rights and ownership of the iPhone are held by Apple.\\n\\nApple designs, manufactures, markets, and sells iPhones through its own retail stores and various carriers around the world. The company holds the intellectual property (IP) rights to the iPhone brand, including trademarks and patents related to the device's design, functionality, and operating system.\\n\\nHowever, it's worth noting that when you purchase an iPhone from Apple or a carrier, you become the owner of the physical device. You are entitled to use the phone as you see fit, install your own apps and software, and sell or trade it in when you're ready to upgrade.\\n\\nBut even after purchasing an iPhone, Apple still retains some rights and responsibilities related to the device, such as:\\n\\n1. Software updates: Apple continues to provide software updates, security patches, and new features for your iPhone.\\n2. Support and warranty: Apple typically provides support and warranties for its products, including iPhones.\\n3. Intellectual property protection: Apple maintains the IP rights to the iPhone's design, functionality, and operating system.\\n\\nSo while you own the physical iPhone, Apple retains some control and responsibility over the device due to its intellectual property rights and software ecosystem.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test LLM without context\n",
    "query = \"Who does iPhone belong to?\"\n",
    "\n",
    "llm.generate(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer is correct but not our story, let's use story as a context and build RAG to answer the questions based on the story**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, we will build a retriever and check that that works well. We will use the story as the context and the questions as the query. We will use the cosine similarity to find the most similar question to the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create retriever to use for the knowledge base\n",
    "chunk_size = 30\n",
    "chunks = split_into_chunks(story, chunk_size=chunk_size)\n",
    "print(f\"Len of chunks: {len(chunks)}\")\n",
    "retriever = Retriever(\n",
    "    vectorizer=embeddings.generate, similarity_metric=cosine_similarity\n",
    ")\n",
    "retriever.add_documents(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieve the most similar chunk to the query\n",
    "top_similar_documents = retriever.retrieve_most_similar(\n",
    "    query, retriever.vectors, top_k=5\n",
    ")\n",
    "top_similar_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see some chunks most similar to the query according to the cosine similarity.\n",
    "\n",
    "\n",
    "😁 Let's build the RAG model to answer the questions based on the story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Who does iPhone belong to?\"\n",
    "\n",
    "# Retrieve relevant context from the knowledge base\n",
    "top_similar_documents = retriever.retrieve_most_similar(\n",
    "    query, retriever.vectors, top_k=5\n",
    ")\n",
    "context = \"\\n\\n\".join([doc[\"document\"] for doc in top_similar_documents])\n",
    "\n",
    "# Generate the prompt\n",
    "prompt = f\"\"\"You goal is to answer the following question: {query} based on the context provided below.\n",
    "\n",
    "{context}\n",
    "--- \n",
    "Answer:\"\"\"\n",
    "\n",
    "# Generate the answer\n",
    "answer = llm.generate(prompt)\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation and extra tasks \n",
    "\n",
    "- `10 points` Base task: Implement the RAG model\n",
    "- `2 point`: Calculate how much token did you use for the prompt and for the responese \n",
    "- `1 point`: Add several documents to the context.\n",
    "- `3 points`: When generating reponse, add links on what document or chunk it is based on. \n",
    "- `3 points`: Add prompt injection protection to the response. \n",
    "- `5-10 points`: Add pre-and post-validation using any guiderail framework to protect from prompt injection, "
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Ihar Nestsiarenia"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
